---
title: "Tarea LSH: Entity matching"
output: html_notebook
---

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
theme_set(theme_bw())
cb_palette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching).

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presentaron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../../datos/similitud/entity_matching/ACM.csv')
dbl <- read_csv('../../datos/similitud/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿sería
factible hacer todas las posibles comparaciones?

**Respuesta*:
```{r}
nrow(acm)*nrow(dbl)
```

```{r}
##2 millones cada documento
2000000*2000000
#4,000,000,000,000.00
```


## Shingling y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos. En este caso escogemos 24 hashes agrupados en 8 bandas, y 
shingles de tamaño 4, y usamos sólo título y autor.

```{r}
acm_1 <- acm %>% select(id, title, authors) %>% 
        mutate(texto = paste(title, authors, sep = "    ")) %>% 
        mutate(origen = "ACM") %>% 
        mutate(id = as.character(id))
dbl_1 <- dbl %>% select(id, title, authors) %>% 
         mutate(texto = paste(title, authors, sep = "    ")) %>% 
         mutate(origen = "DBL")
acm_dbl <- bind_rows(acm_1, dbl_1)
```

**Pregunta**: ¿por qué incluimos algún espacio en blanco entre título y autor?
¿Qué otra estrategia se te ocurre para convertir en tejas?

**Respuesta*: Para que los shingles no traslapen autor y título. También es posible
hacer shingles por separado de autor y título.
Hacer hashes sobre autores, y hashes sobre titulos, y considerar dos hashes.

```{r}
shingle_chars <- function(string, lowercase = TRUE, k = 4){
  # produce shingles (con repeticiones)
  if(lowercase) {
    string <- str_to_lower(string)
  }
  shingles <- seq(1, nchar(string) - k + 1) %>%
    map_chr(function(x) substr(string, x, x + k - 1))
  shingles
}
```

En este ejemplo podemos usar *textreuse*:

```{r}
library(textreuse)
set.seed(88345)
minhasher <- minhash_generator(24)
nombres <- c(acm_1$id, dbl_1$id)
texto <- c(acm_1$texto, dbl_1$texto)
names(texto) <- nombres
corpus <- TextReuseCorpus(text = texto,
                          minhash_func = minhasher,
                          tokenizer = shingle_chars, k = 4, lowercase = TRUE,
                          progress = FALSE, skip_short = FALSE)

```

Construimos las firmas y calculamos cubetas:

```{r}
lsh_conf <- textreuse::lsh(corpus, bands = 8) 
```



**Pregunta**: examina la tabla *lsh_conf*. ¿Qué significa cada columna?
Describe cómo construimos en clase la columna *buckets*.
El hash en la columna bucket se está aplicando la función md5

```{r}
#Cada documento está dividido en 8 bandas
4910*8
head(lsh_conf)
```


**Pregunta**: Haz una gráfica mostrando qué porcentaje de cada nivel
de similitud tiene probabilidad de ser capturado para este problema.
¿Te parece satisfactoria la curva para este problema?
Explica en qué casos esto sería razonable. Si consideras apropiado
cambia estos número.


**Respuesta**: Usamos el código de la clase. Obsérvese que en este
quizá sea mejor una curva más alta alrededor de similitud 0.75, pero 
podemos examinar los datos más adelante para decidir. En esta gráfica
la combinación 5.4 es la que vamos a usar por el momento

```{r}
graficar_curvas <- function(df_br, colour = TRUE){
  r <- df_br$r
  b <- df_br$b
  datos_graf <- data_frame(s = seq(0, 1, 0.01))
  curvas_similitud <- data_frame(b = b, r =r) %>%
                    group_by(r, b) %>%
                    mutate(datos = map2(r, b, function(r, b){
                      datos_graf %>% 
                      mutate(prob = 1 - (1 - s ^ r) ^b)
                    })) %>%
                    unnest
  graf_salida <- ggplot(curvas_similitud, 
                        aes(x = s, y = prob, 
                            colour = as.factor(interaction(b,r)))) +
                 geom_line(size=1.1) + 
                 labs(x = 'similitud', y= 'probablidad de ser candidato',
                      colour = 'b.r') 
  if(colour){
    graf_salida + scale_colour_manual(values=cb_palette)
  }
                 
  graf_salida
}

```
```{r, fig.width=4, fig.asp=0.6}
r <- c(1,2,4,8)
df_br <- data_frame(r = r, b = rev(r))
graficar_curvas(df_br) + geom_vline(xintercept = 0.7)
```

```{r}
df <- data_frame(r = c(5,4,2,1), b = c(4,5,10,20))
graficar_curvas(df) + geom_vline(xintercept = 0.7)
#Esta curva te dice los falsos negativos para casa nivel de similitud 
##   Similitud alta pero se nos fueron
#Por ejemeplo en el nivel 5.4, con similitud 0.7, se tienen
```


## Examinar pares candidatos

Agrupamos cubetas y extraemos pares similares. En *textreuse* se puede
hacer como sigue:

```{r}
candidatos <- lsh_candidates(lsh_conf)
nrow(candidatos)
```

Calculamos también la similitud de jaccard exacta para cada par.

```{r}
candidatos <- lsh_compare(candidatos, corpus, jaccard_similarity)
candidatos
```

**Pregunta**: explica cómo se calcula la columna *score* en la tabla de candidatos. 


Podemos ver el contenido de un texto de esta manera:

```{r}
corpus[["181566"]]$content
corpus[["journals/sigmod/MedeirosP94"]]$content
```


**Pregunta**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total de comparaciones que es posible hacer entre estas dos tablas.

```{r}
#6,001,104 #numero total de comparaciones
## 12,181
```


Ahora eliminamos candidatos que aparecieron en la misma tabla (misma referencia bibliográfica):

```{r}
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(a = id, origen_a = origen))
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(b = id, origen_b = origen))
candidatos_dif <- candidatos %>% filter(origen_a != origen_b)
nrow(candidatos_dif)
```


**Pregunta**: 
¿Cuántos pares candidatos obtuviste?
Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 

```{r}
##Pares de candidatos 
## 6,837
candidatos_dif %>% filter (score == 1)
```
```{r}
acm_1 %>% filter(id == 174642)
#dbl_1 %>$ filter(id == "journals/tods/CliffordC94")
corpus[["174642"]]$content
corpus[["journals/tods/CliffordC94"]]$content
```


**Pregunta**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.

```{r}
candidatos_dif %>% filter (score <= 0.5) ##4,416
candidatos_dif %>% filter (score <= 0.6) ##4,538

```

**Pregunta**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
corpus[["174642"]]$content
corpus[["conf/sigmod/Chong98"]]$content
```

**Pregunta**: ¿cuántos pares candidatos obtuviste al final?

```{r}
candidatos_filt <- filter(candidatos_dif, score >= 0.6)
```


## Examinar pares candidatos


**Pregunta** Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../../datos/similitud/entity_matching/DBLP-ACM_perfectMapping.csv")
```

Crea variables apropiadas para hacer join de los verdaderos matches con tus candidatos:

```{r}
candidatos_filt <- candidatos_filt %>% mutate(idDBLP = ifelse(str_detect(a, "^[0-9]*$"), b, a))
candidatos_filt <- candidatos_filt %>% mutate(idACM = ifelse(str_detect(a, "^[0-9]*$"), a, b))
```

Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping %>% mutate(idACM = as.character(idACM))
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta*: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados?

```{r}
# aquí tu código
precision <- nrow(ambos)/nrow(candidatos_filt)
precision   
recall <- nrow(ambos)/nrow(mapping)
recall
```


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos

```{r}
## código (puedes usar anti-joins)
```

**Pregunta**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?

## Ejercicio final

Corre este ejemplo con un número distinto de hashes y bandas. ¿Puedes obneter buenos resultados
con un número menor de hashes totales (por ejemplo, 4 o 6)? ¿Qué pasa si usas muchas bandas ($b$ con 
pocos hashes ($r$) por banda?


