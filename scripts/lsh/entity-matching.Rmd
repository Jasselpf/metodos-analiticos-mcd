---
title: "Tarea LSH: Entity matching"
output: html_notebook
---



En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching).

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presenteron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../../datos/similitud/entity_matching/ACM.csv')
dbl <- read_csv('../../datos/similitud/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿sería
factible hacer todas las posibles comparaciones?

## Shingling y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos. En este caso escogemos 24 hashes agrupados en 8 bandas, y 
shingles de tamaño 4, y usamos sólo título y autor.

```{r}
acm_1 <- acm %>% select(id, title, authors) %>% 
        mutate(texto = paste(title, authors, sep = "    ")) %>% 
        mutate(origen = "ACM") %>% 
        mutate(id = as.character(id))
dbl_1 <- dbl %>% select(id, title, authors) %>% 
         mutate(texto = paste(title, authors, sep = "    ")) %>% 
         mutate(origen = "DBL")
acm_dbl <- bind_rows(acm_1, dbl_1)
```

**Pregunta**: ¿por qué incluimos algún espacio en blanco entre título y autor?
¿Qué otra estrategia se te ocurre para convertir en tejas?

```{r}
shingle_chars <- function(string, lowercase = TRUE, k = 4){
  # produce shingles (con repeticiones)
  if(lowercase) {
    string <- str_to_lower(string)
  }
  shingles <- seq(1, nchar(string) - k + 1) %>%
    map_chr(function(x) substr(string, x, x + k - 1))
  shingles
}
```

En este ejemplo podemos usar *textreuse*:

```{r}
library(textreuse)
set.seed(88345)
minhasher <- minhash_generator(24)
nombres <- c(acm_1$id, dbl_1$id)
texto <- c(acm_1$texto, dbl_1$texto)
names(texto) <- nombres
corpus <- TextReuseCorpus(text = texto,
                          minhash_func = minhasher,
                          tokenizer = shingle_chars, k = 4, lowercase = TRUE,
                          progress = FALSE, skip_short = FALSE)

```

Construimos las firmas y calculamos cubetas:

```{r}
lsh_conf <- lsh(corpus, bands = 8) 
```



**Pregunta**: examina la tabla *lsh_conf*. ¿Qué significa cada columna?
Describe cómo construimos en clase la columna *buckets*.

**Pregunta**: Haz una gráfica mostrando qué porcentaje de cada nivel
de similitud tiene probabilidad de ser capturado para este problema.
¿Te parece satisfactoria la curva para este problema?
Explica en qué casos esto sería razonable. Si consideras apropiado
cambia estos número.


## Examinar pares candidatos

Agrupamos cubetas y extraemos pares similares. En *textreuse* se puede
hacer como sigue:

```{r}
candidatos <- lsh_candidates(lsh_conf)
nrow(candidatos)
```

Calculamos también la similitud de jaccard exacta para cada par.

```{r}
candidatos <- lsh_compare(candidatos, corpus, jaccard_similarity)
candidatos
```

**Pregunta**: explica cómo se calcula la columna *score* en la tabla de candidatos. 


Podemos ver el contenido de un texto de esta manera:

```{r}
corpus[["181566"]]$content
corpus[["journals/sigmod/MedeirosP94"]]$content
```


**Pregunta**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total
de comparaciones que es posible hacer entre estas dos tablas.

Ahora eliminamos candidatos que aparecieron en la misma tabla (misma referencia bibliográfica):

```{r}
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(a = id, origen_a = origen))
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(b = id, origen_b = origen))
candidatos_dif <- candidatos %>% filter(origen_a != origen_b)
nrow(candidatos_dif)
```


**Pregunta**: 
¿Cuántos pares candidatos obtuviste?
Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 

**Pregunta**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.

```{r}
## aquí tu código
```

**Pregunta**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
```

**Pregunta**: ¿cuántos pares candidatos obtuviste al final?

## Examinar pares candidatos


**Pregunta** Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../../datos/similitud/entity_matching/DBLP-ACM_perfectMapping.csv")
```

Crea variables apropiadas para hacer join de los verdaderos matches con tus candidatos:

```{r}
candidatos_filt <- candidatos_filt %>% mutate(idDBLP = ifelse(str_detect(a, "^[0-9]*$"), b, a))
candidatos_filt <- candidatos_filt %>% mutate(idACM = ifelse(str_detect(a, "^[0-9]*$"), a, b))
```

Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping %>% mutate(idACM = as.character(idACM))
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta*: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados?

```{r}
# aquí tu código
precision <- 
recall <- 
```


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos

```{r}
## código (puedes usar anti-joins)
```

**Pregunta**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?

## Ejercicio final

Corre este ejemplo con un número distinto de hashes y bandas. ¿Puedes obneter buenos resultados
con un número menor de hashes totales (por ejemplo, 4 o 6)? ¿Qué pasa si usas muchas bandas ($b$ con 
pocos hashes ($r$) por banda?


